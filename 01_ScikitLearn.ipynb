{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5aaf5d38-088a-464b-977c-963e86f6e18e",
   "metadata": {},
   "source": [
    "# Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3fbc47-9855-408a-813c-cfb86add5574",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74e782ec-8526-4b27-ab57-50dd07e40ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00549644-4463-43f0-822f-09d1bac67a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data.csv\", sep=\"\\t\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe7b401f-2c56-4e0e-a5b7-641719ec455e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>target</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "      <td>amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1</td>\n",
       "      <td>amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "      <td>amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "      <td>amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "      <td>amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2743</th>\n",
       "      <td>I think food should have flavor and texture an...</td>\n",
       "      <td>0</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2744</th>\n",
       "      <td>Appetite instantly gone.</td>\n",
       "      <td>0</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2745</th>\n",
       "      <td>Overall I was not impressed and would not go b...</td>\n",
       "      <td>0</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2746</th>\n",
       "      <td>The whole experience was underwhelming, and I ...</td>\n",
       "      <td>0</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2747</th>\n",
       "      <td>Then, as if I hadn't wasted enough of my life ...</td>\n",
       "      <td>0</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2748 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  target  source\n",
       "0     So there is no way for me to plug it in here i...       0  amazon\n",
       "1                           Good case, Excellent value.       1  amazon\n",
       "2                                Great for the jawbone.       1  amazon\n",
       "3     Tied to charger for conversations lasting more...       0  amazon\n",
       "4                                     The mic is great.       1  amazon\n",
       "...                                                 ...     ...     ...\n",
       "2743  I think food should have flavor and texture an...       0    yelp\n",
       "2744                           Appetite instantly gone.       0    yelp\n",
       "2745  Overall I was not impressed and would not go b...       0    yelp\n",
       "2746  The whole experience was underwhelming, and I ...       0    yelp\n",
       "2747  Then, as if I hadn't wasted enough of my life ...       0    yelp\n",
       "\n",
       "[2748 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d848973-a4ee-4b0a-96ed-ed2c51f72a87",
   "metadata": {},
   "source": [
    "## Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b777dd25-267b-40fd-a6a0-66e6d4f0acfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e06290f-80e6-43c6-8ad5-59394d4bbc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df[\"sentence\"], df[\"target\"], test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51c7497e-c0cf-4705-bdd5-8ee02d9a1bba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2198,), (2198,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a525ef2b-f2a1-43ed-90e0-ed8de8ce7479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((550,), (550,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29dbb26-3205-44f9-868e-86049d1abecf",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85b28627-b4ea-4bf0-ad51-dbc6bf52077e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8076d1d6-d729-4e99-a599-1415eec528b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(min_df=1, lowercase=True)\n",
    "count_vectorizer.fit(X_train)  # import use only the training!\n",
    "X_train_encoded = count_vectorizer.transform(X_train)\n",
    "X_test_encoded = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90d03ae5-f4cd-49d1-bbbf-2c4e02897d90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2198x4529 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 24039 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f462f25d-dd31-472f-9985-00557c6d4a7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<550x4529 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 5563 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bef4dd-6e18-4a15-9c48-88a31963a046",
   "metadata": {},
   "source": [
    "# MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58421c21-4c83-4181-b396-02b219af29f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.data.pandas_dataset import PandasDataset\n",
    "\n",
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:8080\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6542366e-011a-4f44-9229-39a808bbe996",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BVIEIRA1\\tmp\\hello-mlflow\\.venv\\lib\\site-packages\\mlflow\\data\\dataset_source_registry.py:142: UserWarning: The specified dataset source can be interpreted in multiple ways: LocalArtifactDatasetSource, LocalArtifactDatasetSource. MLflow will assume that this is a LocalArtifactDatasetSource source.\n",
      "  return _dataset_source_registry.resolve(\n"
     ]
    }
   ],
   "source": [
    "dataset: PandasDataset = mlflow.data.from_pandas(df, source=\"data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b723632-e848-45e2-99f0-11830d8ccd2d",
   "metadata": {},
   "source": [
    "## Experiment 1 (Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc7d9598-29b5-4f54-8e15-a6bb5fcecdbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eecb3f18-ee20-481a-9b3c-ac6ffe96e98b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'156473517357470349'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_name = \"sentiment_analysis_logistic_regression\"\n",
    "\n",
    "experiment_tags = {\n",
    "    \"nlp.framework\": \"Scikit Learn\",\n",
    "    \"nlp.encoding\": \"CountVectorizer\",\n",
    "    \"nlp.model\": \"Logistic Regression\",\n",
    "    \"nlp.task\": \"Sentiment Analysis\"\n",
    "}\n",
    "\n",
    "mlflow.create_experiment(name=experiment_name, \n",
    "                         artifact_location=\"mlartifacts\",\n",
    "                         tags=experiment_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c5eb298-b16d-471e-9339-140bbc363287",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BVIEIRA1\\tmp\\hello-mlflow\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\BVIEIRA1\\tmp\\hello-mlflow\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\BVIEIRA1\\tmp\\hello-mlflow\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\BVIEIRA1\\tmp\\hello-mlflow\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\BVIEIRA1\\tmp\\hello-mlflow\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\BVIEIRA1\\tmp\\hello-mlflow\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "{'penalty': 'l2', 'solver': 'lbfgs', 'max_iter': 2}\n",
      "[0.66818182 0.62954545 0.64318182 0.68792711 0.68109339]\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BVIEIRA1\\tmp\\hello-mlflow\\.venv\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  return _infer_schema(self._df)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "{'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 200}\n",
      "[0.83181818 0.82954545 0.79772727 0.82687927 0.82232346]\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BVIEIRA1\\tmp\\hello-mlflow\\.venv\\lib\\site-packages\\_distutils_hack\\__init__.py:18: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "C:\\Users\\BVIEIRA1\\tmp\\hello-mlflow\\.venv\\lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(experiment_name=experiment_name)  # It could be use the ID too\n",
    "\n",
    "params_list = [\n",
    "    {\n",
    "        \"penalty\": \"l2\",\n",
    "        \"solver\": \"lbfgs\",\n",
    "        \"max_iter\": 2\n",
    "    },\n",
    "    {\n",
    "        \"penalty\": \"l2\",\n",
    "        \"solver\": \"liblinear\",\n",
    "        \"max_iter\": 200\n",
    "    }\n",
    "]\n",
    "\n",
    "for params in params_list:\n",
    "\n",
    "    # Cross validation\n",
    "    clf = LogisticRegression(**params, random_state=123)\n",
    "    scores = cross_val_score(estimator=clf, X=X_train_encoded, y=y_train, cv=5)\n",
    "    print(\"-\"*20)\n",
    "    print(params)\n",
    "    print(scores)\n",
    "    print(\"-\"*20)\n",
    "\n",
    "    # Training using all the data\n",
    "    clf.fit(X_train_encoded, y_train)\n",
    "    y_pred = clf.predict(X_test_encoded)\n",
    "    \n",
    "    accuracy = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "    precision = precision_score(y_true=y_test, y_pred=y_pred)\n",
    "    recall = recall_score(y_true=y_test, y_pred=y_pred)\n",
    "    f1 = f1_score(y_true=y_test, y_pred=y_pred)\n",
    "    \n",
    "    metrics = {\n",
    "        \"cv_score\": scores.mean(),\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1\n",
    "    }\n",
    "\n",
    "    run_name = \"_\".join([f\"{k}_{v}\" for k, v in params.items()])\n",
    "    \n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        # Log the hyperparameters\n",
    "        mlflow.log_params(params)\n",
    "    \n",
    "        # Log the metrics\n",
    "        mlflow.log_metrics(metrics)\n",
    "\n",
    "        # Log the dataset\n",
    "        mlflow.log_input(dataset, context=\"training\")\n",
    "    \n",
    "        # Log the model\n",
    "        mlflow.sklearn.log_model(sk_model=clf, \n",
    "                                 artifact_path=\"yelp_model\", \n",
    "                                 input_example=X_train_encoded)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a862447-9afc-48e2-97ed-8158c39e7fdd",
   "metadata": {},
   "source": [
    "## Experiment 2 (Decision Tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "88d643ed-21db-483e-b3c4-59d26f439041",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7f559ec-7657-4d4b-92ed-b08dc6d8a77c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'827846084136165640'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_name = \"sentiment_analysis_decision_tree\"\n",
    "\n",
    "experiment_tags = {\n",
    "    \"nlp.framework\": \"Scikit Learn\",\n",
    "    \"nlp.encoding\": \"CountVectorizer\",\n",
    "    \"nlp.model\": \"Decision Tree\",\n",
    "    \"nlp.task\": \"Sentiment Analysis\"\n",
    "}\n",
    "\n",
    "mlflow.create_experiment(name=experiment_name, \n",
    "                         tags=experiment_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "998c13f9-8d23-4902-b520-5d9d96cc7f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "{'criterion': 'entropy', 'splitter': 'random'}\n",
      "[0.73181818 0.76818182 0.73409091 0.76309795 0.72437358]\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BVIEIRA1\\tmp\\hello-mlflow\\.venv\\lib\\site-packages\\_distutils_hack\\__init__.py:18: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "C:\\Users\\BVIEIRA1\\tmp\\hello-mlflow\\.venv\\lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "{'criterion': 'gini', 'splitter': 'best'}\n",
      "[0.75909091 0.74318182 0.73409091 0.74259681 0.76082005]\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BVIEIRA1\\tmp\\hello-mlflow\\.venv\\lib\\site-packages\\_distutils_hack\\__init__.py:18: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "C:\\Users\\BVIEIRA1\\tmp\\hello-mlflow\\.venv\\lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "# NOTE: THIS CAN BE TURN INTO A FUNCTION INSTEAD OF CODING REPEATED CODE\n",
    "mlflow.set_experiment(experiment_name=experiment_name)  # It could be use the ID too\n",
    "\n",
    "params_list = [\n",
    "    {\n",
    "        \"criterion\": \"entropy\",\n",
    "        \"splitter\": \"random\",\n",
    "    },\n",
    "    {\n",
    "        \"criterion\": \"gini\",\n",
    "        \"splitter\": \"best\",\n",
    "    }\n",
    "]\n",
    "\n",
    "for params in params_list:\n",
    "\n",
    "    # Cross validation\n",
    "    clf = DecisionTreeClassifier(**params, random_state=123)\n",
    "    scores = cross_val_score(estimator=clf, X=X_train_encoded, y=y_train, cv=5)\n",
    "    print(\"-\"*20)\n",
    "    print(params)\n",
    "    print(scores)\n",
    "    print(\"-\"*20)\n",
    "\n",
    "    # Training using all the data\n",
    "    clf.fit(X_train_encoded, y_train)\n",
    "    y_pred = clf.predict(X_test_encoded)\n",
    "    \n",
    "    accuracy = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "    precision = precision_score(y_true=y_test, y_pred=y_pred)\n",
    "    recall = recall_score(y_true=y_test, y_pred=y_pred)\n",
    "    f1 = f1_score(y_true=y_test, y_pred=y_pred)\n",
    "    \n",
    "    metrics = {\n",
    "        \"cv_score\": scores.mean(),\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1\n",
    "    }\n",
    "\n",
    "    run_name = \"_\".join([f\"{k}_{v}\" for k, v in params.items()])\n",
    "    \n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        # Log the hyperparameters\n",
    "        mlflow.log_params(params)\n",
    "    \n",
    "        # Log the metrics\n",
    "        mlflow.log_metrics(metrics)\n",
    "\n",
    "        # Log the dataset\n",
    "        mlflow.log_input(dataset, context=\"training\")\n",
    "    \n",
    "        # Log the model\n",
    "        mlflow.sklearn.log_model(sk_model=clf, \n",
    "                                 artifact_path=\"yelp_model\", \n",
    "                                 input_example=X_train_encoded)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c14a40-b51e-4fb3-b22a-e09520ef9e41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
