{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c40be3a8-e59e-4e44-a5bf-020386e24cac",
   "metadata": {},
   "source": [
    "# PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e4c0bcf-dc0c-4a61-8ebe-489e6e04673b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Random Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a242b93-7bbe-44aa-a831-0e304529e52a",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6b14fdc-5fad-46ce-afdb-98ecbafc32db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a16c5bf-9002-4463-b32a-69171eecfddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data.csv\", sep=\"\\t\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "306887d7-bffc-488d-affd-6596d7319220",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"source\"] == \"yelp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a741909b-71f6-4d8f-9522-e0c229449d6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>target</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1748</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1749</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1750</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1751</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1752</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2743</th>\n",
       "      <td>I think food should have flavor and texture an...</td>\n",
       "      <td>0</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2744</th>\n",
       "      <td>Appetite instantly gone.</td>\n",
       "      <td>0</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2745</th>\n",
       "      <td>Overall I was not impressed and would not go b...</td>\n",
       "      <td>0</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2746</th>\n",
       "      <td>The whole experience was underwhelming, and I ...</td>\n",
       "      <td>0</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2747</th>\n",
       "      <td>Then, as if I hadn't wasted enough of my life ...</td>\n",
       "      <td>0</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  target source\n",
       "1748                           Wow... Loved this place.       1   yelp\n",
       "1749                                 Crust is not good.       0   yelp\n",
       "1750          Not tasty and the texture was just nasty.       0   yelp\n",
       "1751  Stopped by during the late May bank holiday of...       1   yelp\n",
       "1752  The selection on the menu was great and so wer...       1   yelp\n",
       "...                                                 ...     ...    ...\n",
       "2743  I think food should have flavor and texture an...       0   yelp\n",
       "2744                           Appetite instantly gone.       0   yelp\n",
       "2745  Overall I was not impressed and would not go b...       0   yelp\n",
       "2746  The whole experience was underwhelming, and I ...       0   yelp\n",
       "2747  Then, as if I hadn't wasted enough of my life ...       0   yelp\n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed29440-1f36-4332-b5b6-54343cf81761",
   "metadata": {},
   "source": [
    "## Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "843c0b6c-28c1-4c34-990c-8ab1a344d7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cde779b7-41b5-4f96-96d7-bc2fab1b32cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df[\"sentence\"], df[\"target\"], test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6577077-0894-4bd2-99c1-5593adf24f65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((800,), (800,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fcbd194-33ef-49a3-8252-50f58850d4f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200,), (200,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a03bafb-e3c8-4f9a-971f-cf06fe183677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\BVIEIRA1\\tmp\\hello-mlflow\\.venv\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "NUM_WORDS = 5000\n",
    "MAX_LEN = 100\n",
    "\n",
    "tokenizer = Tokenizer(num_words=NUM_WORDS)\n",
    "tokenizer.fit_on_texts(X_train)  # Important be only the train data!!!\n",
    "\n",
    "X_train_encoded = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_encoded = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "X_train_encoded = pad_sequences(X_train_encoded, maxlen=MAX_LEN, padding=\"post\")\n",
    "X_test_encoded = pad_sequences(X_test_encoded, maxlen=MAX_LEN, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92dbebe6-a2e7-4d94-9881-5aeab07758e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "batch_size = 256\n",
    "X_train_tensor = torch.tensor(X_train_encoded, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test_encoded, dtype=torch.long)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32)\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1c6ae2-2dd6-4b1d-a644-c254cc54c44a",
   "metadata": {},
   "source": [
    "# MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03880cc3-14e6-4f7c-9e36-60f3167214e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.data.pandas_dataset import PandasDataset\n",
    "\n",
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:8080\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f7a3f9f-3601-4b03-afa8-078044485794",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BVIEIRA1\\tmp\\hello-mlflow\\.venv\\lib\\site-packages\\mlflow\\data\\dataset_source_registry.py:142: UserWarning: The specified dataset source can be interpreted in multiple ways: LocalArtifactDatasetSource, LocalArtifactDatasetSource. MLflow will assume that this is a LocalArtifactDatasetSource source.\n",
      "  return _dataset_source_registry.resolve(\n"
     ]
    }
   ],
   "source": [
    "dataset: PandasDataset = mlflow.data.from_pandas(df, source=\"data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7989acd-bef7-4a63-987e-c0ac068640b0",
   "metadata": {},
   "source": [
    "# Experiment 4 (PyTorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2be28b83-bcc0-4d5a-bf90-3c394a967453",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6902db47-394d-4d0a-af67-51b9a83a8382",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, vocab_size, out_channels, kernel_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, 50)\n",
    "        self.cnn = nn.Conv1d(in_channels=MAX_LEN, \n",
    "                             out_channels=out_channels,\n",
    "                             kernel_size=kernel_size,\n",
    "                             padding=int((kernel_size - 1)/2))\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2)\n",
    "        self.fc = nn.Linear(int((out_channels * 50)/2), 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        x = F.relu(self.cnn(embedded)).view(embedded.size(0), -1)\n",
    "        x = self.pool(x)\n",
    "        output = self.fc(x)\n",
    "        return torch.sigmoid(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "734b5727-07b6-4b24-bafb-a720d4f6c879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'737991649699542434'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_name = \"sentiment_analysis_torch_cnn\"\n",
    "\n",
    "experiment_tags = {\n",
    "    \"nlp.framework\": \"PyTorch\",\n",
    "    \"nlp.encoding\": \"Tokenizer\",\n",
    "    \"nlp.model\": \"CNN Network\",\n",
    "    \"nlp.task\": \"Sentiment Analysis\"\n",
    "}\n",
    "\n",
    "mlflow.create_experiment(name=experiment_name,\n",
    "                         artifact_location=\"mlartifacts\",\n",
    "                         tags=experiment_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92b87170-e703-44b8-b6e6-25e2d5e0f1e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (embedding): Embedding(1807, 50)\n",
      "  (cnn): Conv1d(100, 32, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "  (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc): Linear(in_features=800, out_features=1, bias=True)\n",
      ")\n",
      "Epoch [1/10], Loss: 0.7173, Accuracy: 0.5162\n",
      "Epoch [2/10], Loss: 0.7025, Accuracy: 0.5288\n",
      "Epoch [3/10], Loss: 0.6815, Accuracy: 0.5637\n",
      "Epoch [4/10], Loss: 0.6811, Accuracy: 0.5375\n",
      "Epoch [5/10], Loss: 0.6731, Accuracy: 0.6425\n",
      "Epoch [6/10], Loss: 0.6605, Accuracy: 0.6650\n",
      "Epoch [7/10], Loss: 0.6534, Accuracy: 0.6600\n",
      "Epoch [8/10], Loss: 0.6568, Accuracy: 0.5212\n",
      "Epoch [9/10], Loss: 0.6488, Accuracy: 0.6763\n",
      "Epoch [10/10], Loss: 0.6501, Accuracy: 0.6475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BVIEIRA1\\tmp\\hello-mlflow\\.venv\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  return _infer_schema(self._df)\n",
      "C:\\Users\\BVIEIRA1\\tmp\\hello-mlflow\\.venv\\lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (embedding): Embedding(1807, 50)\n",
      "  (cnn): Conv1d(100, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc): Linear(in_features=3200, out_features=1, bias=True)\n",
      ")\n",
      "Epoch [1/40], Loss: 0.8121, Accuracy: 0.4888\n",
      "Epoch [2/40], Loss: 0.7303, Accuracy: 0.5162\n",
      "Epoch [3/40], Loss: 0.6782, Accuracy: 0.5400\n",
      "Epoch [4/40], Loss: 0.6932, Accuracy: 0.5175\n",
      "Epoch [5/40], Loss: 0.6708, Accuracy: 0.5725\n",
      "Epoch [6/40], Loss: 0.6597, Accuracy: 0.6125\n",
      "Epoch [7/40], Loss: 0.6537, Accuracy: 0.6275\n",
      "Epoch [8/40], Loss: 0.6437, Accuracy: 0.5850\n",
      "Epoch [9/40], Loss: 0.6217, Accuracy: 0.7225\n",
      "Epoch [10/40], Loss: 0.6270, Accuracy: 0.6850\n",
      "Epoch [11/40], Loss: 0.6160, Accuracy: 0.7000\n",
      "Epoch [12/40], Loss: 0.6061, Accuracy: 0.7350\n",
      "Epoch [13/40], Loss: 0.5933, Accuracy: 0.7100\n",
      "Epoch [14/40], Loss: 0.6060, Accuracy: 0.7137\n",
      "Epoch [15/40], Loss: 0.5798, Accuracy: 0.7400\n",
      "Epoch [16/40], Loss: 0.5482, Accuracy: 0.8013\n",
      "Epoch [17/40], Loss: 0.5537, Accuracy: 0.7388\n",
      "Epoch [18/40], Loss: 0.5496, Accuracy: 0.7675\n",
      "Epoch [19/40], Loss: 0.5187, Accuracy: 0.8525\n",
      "Epoch [20/40], Loss: 0.4977, Accuracy: 0.8100\n",
      "Epoch [21/40], Loss: 0.4833, Accuracy: 0.8200\n",
      "Epoch [22/40], Loss: 0.4667, Accuracy: 0.8675\n",
      "Epoch [23/40], Loss: 0.4555, Accuracy: 0.8688\n",
      "Epoch [24/40], Loss: 0.4377, Accuracy: 0.8812\n",
      "Epoch [25/40], Loss: 0.4305, Accuracy: 0.8738\n",
      "Epoch [26/40], Loss: 0.4063, Accuracy: 0.8688\n",
      "Epoch [27/40], Loss: 0.3935, Accuracy: 0.8600\n",
      "Epoch [28/40], Loss: 0.4009, Accuracy: 0.8375\n",
      "Epoch [29/40], Loss: 0.3573, Accuracy: 0.8738\n",
      "Epoch [30/40], Loss: 0.3515, Accuracy: 0.8812\n",
      "Epoch [31/40], Loss: 0.3473, Accuracy: 0.8862\n",
      "Epoch [32/40], Loss: 0.3506, Accuracy: 0.8900\n",
      "Epoch [33/40], Loss: 0.3447, Accuracy: 0.9000\n",
      "Epoch [34/40], Loss: 0.3028, Accuracy: 0.9387\n",
      "Epoch [35/40], Loss: 0.2950, Accuracy: 0.9387\n",
      "Epoch [36/40], Loss: 0.2682, Accuracy: 0.9475\n",
      "Epoch [37/40], Loss: 0.2446, Accuracy: 0.9500\n",
      "Epoch [38/40], Loss: 0.2380, Accuracy: 0.9587\n",
      "Epoch [39/40], Loss: 0.2280, Accuracy: 0.9563\n",
      "Epoch [40/40], Loss: 0.2430, Accuracy: 0.9587\n",
      "Net(\n",
      "  (embedding): Embedding(1807, 50)\n",
      "  (cnn): Conv1d(100, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "  (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc): Linear(in_features=3200, out_features=1, bias=True)\n",
      ")\n",
      "Epoch [1/60], Loss: 0.9141, Accuracy: 0.4963\n",
      "Epoch [2/60], Loss: 0.8175, Accuracy: 0.5413\n",
      "Epoch [3/60], Loss: 0.7283, Accuracy: 0.5288\n",
      "Epoch [4/60], Loss: 0.6787, Accuracy: 0.5550\n",
      "Epoch [5/60], Loss: 0.6734, Accuracy: 0.5600\n",
      "Epoch [6/60], Loss: 0.6599, Accuracy: 0.5200\n",
      "Epoch [7/60], Loss: 0.6485, Accuracy: 0.6138\n",
      "Epoch [8/60], Loss: 0.6437, Accuracy: 0.5863\n",
      "Epoch [9/60], Loss: 0.6198, Accuracy: 0.6863\n",
      "Epoch [10/60], Loss: 0.6242, Accuracy: 0.6737\n",
      "Epoch [11/60], Loss: 0.6106, Accuracy: 0.6837\n",
      "Epoch [12/60], Loss: 0.6007, Accuracy: 0.7312\n",
      "Epoch [13/60], Loss: 0.5826, Accuracy: 0.8025\n",
      "Epoch [14/60], Loss: 0.5709, Accuracy: 0.7987\n",
      "Epoch [15/60], Loss: 0.5623, Accuracy: 0.7562\n",
      "Epoch [16/60], Loss: 0.5535, Accuracy: 0.7712\n",
      "Epoch [17/60], Loss: 0.5227, Accuracy: 0.7887\n",
      "Epoch [18/60], Loss: 0.5048, Accuracy: 0.8013\n",
      "Epoch [19/60], Loss: 0.5060, Accuracy: 0.8213\n",
      "Epoch [20/60], Loss: 0.4807, Accuracy: 0.8500\n",
      "Epoch [21/60], Loss: 0.4551, Accuracy: 0.8612\n",
      "Epoch [22/60], Loss: 0.4333, Accuracy: 0.8588\n",
      "Epoch [23/60], Loss: 0.4428, Accuracy: 0.8488\n",
      "Epoch [24/60], Loss: 0.4134, Accuracy: 0.8550\n",
      "Epoch [25/60], Loss: 0.4079, Accuracy: 0.8662\n",
      "Epoch [26/60], Loss: 0.3883, Accuracy: 0.8550\n",
      "Epoch [27/60], Loss: 0.4250, Accuracy: 0.8075\n",
      "Epoch [28/60], Loss: 0.3724, Accuracy: 0.8675\n",
      "Epoch [29/60], Loss: 0.3486, Accuracy: 0.8925\n",
      "Epoch [30/60], Loss: 0.3427, Accuracy: 0.8975\n",
      "Epoch [31/60], Loss: 0.3302, Accuracy: 0.9075\n",
      "Epoch [32/60], Loss: 0.3237, Accuracy: 0.9137\n",
      "Epoch [33/60], Loss: 0.2778, Accuracy: 0.9250\n",
      "Epoch [34/60], Loss: 0.2742, Accuracy: 0.9337\n",
      "Epoch [35/60], Loss: 0.2617, Accuracy: 0.9375\n",
      "Epoch [36/60], Loss: 0.2349, Accuracy: 0.9400\n",
      "Epoch [37/60], Loss: 0.2558, Accuracy: 0.9387\n",
      "Epoch [38/60], Loss: 0.2153, Accuracy: 0.9387\n",
      "Epoch [39/60], Loss: 0.2131, Accuracy: 0.9413\n",
      "Epoch [40/60], Loss: 0.2333, Accuracy: 0.9513\n",
      "Epoch [41/60], Loss: 0.1987, Accuracy: 0.9525\n",
      "Epoch [42/60], Loss: 0.1694, Accuracy: 0.9625\n",
      "Epoch [43/60], Loss: 0.1836, Accuracy: 0.9613\n",
      "Epoch [44/60], Loss: 0.1570, Accuracy: 0.9637\n",
      "Epoch [45/60], Loss: 0.1807, Accuracy: 0.9537\n",
      "Epoch [46/60], Loss: 0.1465, Accuracy: 0.9650\n",
      "Epoch [47/60], Loss: 0.1461, Accuracy: 0.9725\n",
      "Epoch [48/60], Loss: 0.1445, Accuracy: 0.9775\n",
      "Epoch [49/60], Loss: 0.1255, Accuracy: 0.9775\n",
      "Epoch [50/60], Loss: 0.1355, Accuracy: 0.9537\n",
      "Epoch [51/60], Loss: 0.1598, Accuracy: 0.9600\n",
      "Epoch [52/60], Loss: 0.1324, Accuracy: 0.9825\n",
      "Epoch [53/60], Loss: 0.1188, Accuracy: 0.9762\n",
      "Epoch [54/60], Loss: 0.1244, Accuracy: 0.9663\n",
      "Epoch [55/60], Loss: 0.1217, Accuracy: 0.9625\n",
      "Epoch [56/60], Loss: 0.1160, Accuracy: 0.9587\n",
      "Epoch [57/60], Loss: 0.1008, Accuracy: 0.9775\n",
      "Epoch [58/60], Loss: 0.0888, Accuracy: 0.9788\n",
      "Epoch [59/60], Loss: 0.0888, Accuracy: 0.9838\n",
      "Epoch [60/60], Loss: 0.0942, Accuracy: 0.9725\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(experiment_name=experiment_name)  # It could be use the ID too\n",
    "\n",
    "params_list = [\n",
    "    {\n",
    "        \"out_channels\": 32,\n",
    "        \"kernel_size\": 5,\n",
    "        \"epochs\": 10\n",
    "    },\n",
    "    {\n",
    "        \"out_channels\": 128,\n",
    "        \"kernel_size\": 3,\n",
    "        \"epochs\": 40\n",
    "    },\n",
    "    {\n",
    "        \"out_channels\": 128,\n",
    "        \"kernel_size\": 5,\n",
    "        \"epochs\": 60\n",
    "    }\n",
    "]\n",
    "\n",
    "for i, params in enumerate(params_list):\n",
    "\n",
    "    model = Net(vocab_size=len(tokenizer.index_word) + 1, \n",
    "                out_channels=params[\"out_channels\"], \n",
    "                kernel_size=params[\"kernel_size\"])\n",
    "    print(model)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Train the model\n",
    "    num_epochs = params[\"epochs\"]\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels.unsqueeze(1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            predicted = (outputs > 0.5).float()\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels.unsqueeze(1)).sum().item()\n",
    "            \n",
    "        average_loss = total_loss / len(train_loader)\n",
    "        accuracy = correct / total\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {average_loss:.4f}, Accuracy: {accuracy:.4f}')\n",
    "\n",
    "    # Evaluate the model\n",
    "    model.eval()\n",
    "    y_pred = []\n",
    "    y_test = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            predicted = (outputs > 0.5).float()\n",
    "            y_pred.extend(predicted.squeeze().tolist())\n",
    "            y_test.extend(labels.tolist())\n",
    "    \n",
    "    accuracy = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "    precision = precision_score(y_true=y_test, y_pred=y_pred)\n",
    "    recall = recall_score(y_true=y_test, y_pred=y_pred)\n",
    "    f1 = f1_score(y_true=y_test, y_pred=y_pred)\n",
    "    \n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1\n",
    "    }\n",
    "    \n",
    "    run_name = \"_\".join([f\"{k}_{v}\" for k, v in params.items()])\n",
    "    \n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        # Log the hyperparameters\n",
    "        mlflow.log_params(params)\n",
    "    \n",
    "        # Log the metrics\n",
    "        mlflow.log_metrics(metrics)\n",
    "\n",
    "        # Log the dataset\n",
    "        mlflow.log_input(dataset, context=\"training\")\n",
    "\n",
    "    \n",
    "        # Log the model\n",
    "        mlflow.pytorch.save_model(pytorch_model=model, \n",
    "                                  path=f\"models/yelp_model_torch_{i}\", \n",
    "                                  input_example=X_train_encoded)\n",
    "\n",
    "        mlflow.log_artifact(f\"models/yelp_model_torch_{i}\", artifact_path=\"mlartifacts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9a308c-b9b9-4892-a425-c0add26e1978",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
